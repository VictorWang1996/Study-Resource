## 一.计算机网络
### 1.get请求和post请求的区别
> 1、GET请求一般用去请求获取数据，POST一般作为发送数据到后台时使用    
2、GET请求也可传参到后台，但是其参数在浏览器的地址栏的url中可见，所以隐私性安全性较差，且参数长度也是有限制的  
  POST请求传递参数放在Request body中，不会在url中显示，比GET要安全，且参数长度无限制  
3、GET请求刷新浏览器或回退时没有影响,POST回退时会重新提交数据请求  
4、GET 请求可被缓存,POST 请求不会被缓存  
5、GET 请求保留在浏览器历史记录中,POST 请求不会保留在浏览器历史记录中  
6、GET 请求可被收藏为书签,POST 不能被收藏为书签  
7、GET请求只能进行url编码（application/x-www-form-urlencoded）  
  POST支持多种编码方式（application/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。）  
8、GET请求比较常见的方式是通过url地址栏请求,POST最常见是通过form表单发送数据请求  
9.GET产生一个TCP数据包；POST产生两个TCP数据包  
长的说：  
对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；  
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。  
也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。  

### 2.在浏览器网址输入一个url后直到浏览器显示页面的过程(这边面试官可能会详细的考察DNS服务器的知识)
> **一、网络通信**  
> 互联网内各网络设备间的通信都遵循TCP/IP协议，利用TCP/IP协议族进行网络通信时，会通过分层顺序与对方进行通信。分层由高到低分别为：应用层、传输层、网络层、数据链路层。发送端从应用层往下走，接收端从数据链路层网上走。  
> **TCP/IP**  
> 1.在浏览器中输入url
> 用户输入url，例如http://www.baidu.com。 其中http为协议，www.baidu.com 为网络地址，及指出需要的资源在那台计算机上。一般网络地址可以为域名或IP地址，此处为域名。使用域名是为了方便记忆，但是为了让计算机理解这个地址还需要把它解析为IP地址。  
> 2.应用层DNS解析域名  
>    客户端先检查本地是否有对应的IP地址，若找到则返回响应的IP地址。若没找到则请求上级DNS服务器，直至找到或到根节点。  
> **DNS中递归查询和迭代查询的区别**  
> 递归查询： 一般客户机和服务器之间属递归查询，即当客户机向DNS服务器发出请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到结果后转交客户机。  
> 迭代查询（反复查询）： 一般DNS服务器之间属迭代查询，如：若DNS2不能响应DNS1的请求，则它会将DNS3的IP给DNS2，以便其再向DNS3发出请求。  
> 以一个DNS请求解析为例：  
> 1）用户发起域名请求到dnsA，这时dnsA有这个记录，将结果返回给用户，这个过程是递归查询。  
> 2）用户发起域名请求到dnsA，这时dns没有这个记录，它去向dnsB问有没有这个记录，以此类推，直到把结果返回给用户，这个过程是递归查询。  
> 3）用户发起域名请求到dnsA，这时dnsA没有这个记录，它告诉用户，我没有这个记录，你去问dnsB吧，这个过程是迭代查询。  
> 3.应用层客户端发送HTTP请求  
> HTTP请求包括请求报头和请求主体两个部分，其中请求报头包含了至关重要的信息，包括请求的方法（GET / POST）、目标url、遵循的协议（http / https / ftp…），返回的信息是否需要缓存，以及客户端是否发送cookie等。  
> 4.传输层TCP传输报文  
>    位于传输层的TCP协议为传输报文提供可靠的字节流服务。它为了方便传输，将大块的数据分割成以报文段为单位的数据包进行管理，并为它们编号，方便服务器接收时能准确地还原报文信息。TCP协议通过“三次握手”等方法保证传输的安全可靠。
>   “三次握手”的过程是，发送端先发送一个带有SYN（synchronize）标志的数据包给接收端，在一定的延迟时间内等待接收的回复。接收端收到数据包后，传回一个带有SYN/ACK标志的数据包以示传达确认信息。接收方收到后再发送一个带有ACK标志的数据包给接收端以示握手成功。在这个过程中，如果发送端在规定延迟时间内没有收到回复则默认接收方没有收到请求，而再次发送，直到收到回复为止。  
> **TCP**  
> 5.网络层IP协议查询MAC地址
>   IP协议的作用是把TCP分割好的各种数据包传送给接收方。而要保证确实能传到接收方还需要接收方的MAC地址，也就是物理地址。IP地址和MAC地址是一一对应的关系，一个网络设备的IP地址可以更换，但是MAC地址一般是固定不变的。ARP协议可以将IP地址解析成对应的MAC地址。当通信的双方不在同一个局域网时，需要多次中转才能到达最终的目标，在中转的过程中需要通过下一个中转站的MAC地址来搜索下一中转目标。  
> 6.数据到达数据链路层  
>   在找到对方的MAC地址后，就将数据发送到数据链路层传输。这时，客户端发送请求的阶段结束  
> 7.服务器接收数据  
>   接收端的服务器在链路层接收到数据包，再层层向上直到应用层。这过程中包括在运输层通过TCP协议讲分段的数据包重新组成原来的HTTP请求报文。  
> 8.服务器响应请求  
>   服务接收到客户端发送的HTTP请求后，查找客户端请求的资源，并返回响应报文，响应报文中包括一个重要的信息——状态码。状态码由三位数字组成，其中比较常见的是200 OK表示请求成功。301表示永久重定向，即请求的资源已经永久转移到新的位置。在返回301状态码的同时，响应报文也会附带重定向的url，客户端接收到后将http请求的url做相应的改变再重新发送。404 not found 表示客户端请求的资源找不到。    
> 9.服务器返回相应文件  
>   请求成功后，服务器会返回相应的HTML文件。接下来就到了页面的渲染阶段了。   
> **二、页面渲染**  
>    现代浏览器渲染页面的过程是这样的：jiexiHTML以构建DOM树 –构建渲染树 –布局渲染树 –绘制渲染树。
>    DOM树是由HTML文件中的标签排列组成，渲染树是在DOM树中加入CSS或HTML中的style样式而形成。渲染树只包含需要显示在页面中的DOM元素，像<head>元素或display属性值为none的元素都不在渲染树中。
>    在浏览器还没接收到完整的HTML文件时，它就开始渲染页面了，在遇到外部链入的脚本标签或样式标签或图片时，会再次发送HTTP请求重复上述的步骤。在收到CSS文件后会对已经渲染的页面重新渲染，加入它们应有的样式，图片文件加载完立刻显示在相应位置。在这一过程中可能会触发页面的重绘或重排。  
### 3.tcp三次握手和四次挥手的过程(为什么不可以两次握手，为什么握手要三次，挥手需要四次)   ###
> **三次握手**  
> ![](https://mmbiz.qpic.cn/mmbiz_jpg/FIXT5d3vGcpUvnYVlGTOia56vzkkfpOzsBXlH6uJ4vnINhf28NbOomibRefLXyib2BjLdFkL0mMlbf1A8dP9lUY9A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
> 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。
> 具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”  
**四次挥手**  
![](https://mmbiz.qpic.cn/mmbiz_jpg/FIXT5d3vGcpUvnYVlGTOia56vzkkfpOzsuefPiba80E8ibIg1iccQCdXm4f2YlDiaBkZiamxoSvCtMBMMCAwKs7WruFg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
> 因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。
> 由于 TCP 协议是全双工的，也就是说客户端和服务端都可以发起断开连接。两边各发起一次断开连接的申请，加上各自的两次确认，看起来就像执行了四次挥手。
### 4.七层OSI模型或TCP/IP协议模型(各层分别实现了什么协议)   ###

|OSI中的层|功能TCP|IP协议族|  
| --- | --- | --- |  
|应用层|文件传输，电子邮件，文件服务，虚拟终端|TFTP，HTTP，SNMP，FTP，SMTP，DNS，RIP，Telnet|  
|表示层|	数据格式化，代码转换，数据加密|	无|  
|会话层|	控制应用程序之间会话能力；如不同软件数据分发给不同软件	|ASAP、TLS、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、Winsock、BSD sockets|  
|传输层|	端到端传输数据的基本功能|TCP、UDP|  
|网络层|	定义IP编址，定义路由功能；如不同设备的数据转发|IP，ICMP，RIP，OSPF，BGP，IGMP|  
|数据链路层|定义数据的基本格式，如何传输，如何标识|SLIP，CSLIP，PPP，ARP，RARP，MTU|  
|物理层|以二进制数据形式在物理媒体上传输数据|ISO2110，IEEE802|
### 5.各种io模型的知识(BIO,NIO,AIO)   ###

> **BIO** 就是传统的 java.io 包，它是基于流模型实现的，交互的方式是同步、阻塞方式，也就是说在读入输入流或者输出流时，在读写动作完成之前，线程会一直阻塞在那里，它们之间的调用时可靠的线性顺序。它的有点就是代码比较简单、直观；缺点就是 IO 的效率和扩展性很低，容易成为应用性能瓶颈。（一连接一线程）  
**NIO** 是 Java 1.4 引入的 java.nio 包，提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层高性能的数据操作方式。  
![](https://img-blog.csdnimg.cn/20190422121139668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM4MTA5MDQ2,size_16,color_FFFFFF,t_70)
![](https://img-blog.csdnimg.cn/20190422121151244.png)
**AIO** 是 Java 1.7 之后引入的包，是 NIO 的升级版本，提供了异步非堵塞的 IO 操作方式，所以人们叫它 AIO（Asynchronous IO），异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。  
### 6.http协议和tcp协议的区别  

> TCP协议是传输层协议，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。
TCP协议对应传输层，，而HTTP协议对应应用层，从本质上说，Http协议是建立在TCP协议基础之上的。当浏览器需要从服务器 获取网页数据的时候，会发出一次http请求。Http通过TCP建立起一个到服务器的通道。简单的说，当一个网页完成之后，客户端和服务器端之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个页面时，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件中设定这个时间，Http是无状态的连接，TCP是有状态的长连接。
### 7.https和http的区别
> https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
> http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
> http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
> http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
### 8.http和https的请求过程   ###
http：  
![](https://mmbiz.qpic.cn/mmbiz_jpg/FIXT5d3vGcpUvnYVlGTOia56vzkkfpOzsSUH8DWIV0lPWBiamYMAAGU9sGEiaS163Tglica6BT2ZPLHeBjtx7gxuCg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
https：  
![](https://mmbiz.qpic.cn/mmbiz_jpg/FIXT5d3vGcpUvnYVlGTOia56vzkkfpOzsHuO3DiaWcH1ewBrT1Gc3qAaWa8zGPTa8RicibcseMurwk9hDT3jkHR36A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
### 9.http协议的发展历程

> **HTTP/0.9**   
HTTP协议的最初版本，功能简陋，仅支持 GET 方法，并且仅能请求访问 HTML 格式的资源  
**HTTP/1.0**  
增加了请求方式 POST 和 HEAD  
不再局限于0.9版本的HTML格式，根据Content-Type可以支持多种数据格式，即MIME多用途互联网邮件扩展，例如text/html、image/jpeg等  
同时也开始支持 cache，就是当客户端在规定时间内访问统一网站，直接访问cache即可  
HTTP请求和回应的格式也变了。除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。其他的新增功能还包括状态码（status code）、多字符集支持、多部分发送（multi-part type）、权限（authorization）、缓存（cache）、内容编码（content encoding）等  
但是1.0版本的工作方式是每次TCP连接只能发送一个请求，当服务器响应后就会关闭这次连接，下一个请求需要再次建立TCP连接，就是不支持keepalive  
**HTTP/1.0+**  
在20世纪90年代中叶，为满足飞快发展的万维网，很多流行的 Web 客户端和服务器飞快的向 HTTP 中添加各种特性，包括持久的 keep-alive 连接、虚拟主机支持，以及代理连接支持都被假如到 HTTP 中，并称为非官方的事实标准。这种非正式的 HTTP 扩展版本通常称为 HTTP/1.0+  
**HTTP/1.1**  
http1.1是目前最为主流的http协议版本，从1997年发布至今，仍是主流的http协议版本。
引入了持久连接，或叫长连接（ persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。  
引入了管道机制（ pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率。  
新增方法：PUT、 PATCH、 OPTIONS、 DELETE。  
http协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度。  
**HTTP/2.0（又名 HTTP-NG）**  
http/2发布于2015年，目前应用还比较少。  
http/2是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。  
复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了队头堵塞的问题,此双向的实时通信称为多工（ Multiplexing）。  
HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送。  
引入头信息压缩机制（ header compression） ,头信息使用gzip或compress压缩后再发送。   
**HTTP2.0和HTTP1.X相比的新特性**  
新的二进制格式（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。  
多路复用（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。  
header压缩，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。  
服务端推送（server push），同SPDY一样，HTTP2.0也具有server push功能。      
### 10.lvs，nginx，HA在七层网络协议中分别作用于哪层，各自的区别   

> lvs:3,4 -LVS的通过控制IP来实现负载均衡。  
nginx:4,5,6,7  
HA:一种是HTTP模式，属于7层分发，另外一种是TCP模式，属于4层分发。  
### 11.tpc如何实现可靠传输(如何实现udp的可靠传输)   
> 超时重传（定时器）
> 
> 有序接受 （添加包序号）
> 
> 应答确认 （Seq/Ack应答机制）
> 
> 滑动窗口流量控制等机制 （滑动窗口协议）
### 12.tcp和udp的区别  
||TCP|	UDP|  
| --- | --- | --- |  
|连接性|	面向连接|	面向非连接|  
|传输可靠性|	可靠|	不可靠|  
|报文|	面向字节流|	面向报文| 
|效率|	传输效率低|	传输效率高|  
|流量控制|	滑动窗口|	无|  
|拥塞控制|	慢开始、拥塞避免、快重传、快恢复|	无|  
|传输速度|	慢|	快|  
|应用场合|	对效率要求低，对准确性要求高或要求有连接的场景|	对效率要求高，对准确性要求低|  

### 13.为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？
> 客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。等待2MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。
## 二.操作系统
### 1.线程和进程的区别(可能会问到协程)  
> 进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。  
**根本区别：**进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位  
**开销方面：**每个进程都有独立的代码和数据空间（程序上下文），进程之间切换开销大；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小  
**所处环境：**在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行）  
**内存分配：**系统为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源  
**包含关系：**线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程  
**协程：**协程（Coroutines）是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。
协程既不是进程也不是线程，协程仅仅是一个特殊的函数，协程它进程和进程不是一个维度的。
一个进程可以包含多个线程，一个线程可以包含多个协程。
一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。
协程与进程一样，切换是存在上下文切换问题的。
![](https://upload-images.jianshu.io/upload_images/4933701-4a7846c5d7c1290c.png?imageMogr2/auto-orient/strip|imageView2/2/w/646/format/webp)

### 2.进程的调度算法

> **批处理系统**  
> 1.1 先来先服务 first-come first-serverd（FCFS）  
非抢占式的调度算法，按照请求的顺序进行调度。  
有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。  
1.2 短作业优先 shortest job first（SJF）  
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。  
长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。  
1.3 最短剩余时间优先 shortest remaining time next（SRTN）  
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。  
**交互式系统**  
2.1 时间片轮转  
将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。  
2.2 优先级调度  
为每个进程分配一个优先级，按优先级进行调度。  
为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。  
2.3 多级反馈队列  
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。  
多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。  
每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。  
可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。  
**实时系统**  
实时系统要求一个请求在一个确定时间内得到响应。  
分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。  
  
### 3.linux中几种io模型(select,poll,epoll)   
> select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。  
> (1)select==>时间复杂度O(n)  
它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。  
(2)poll==>时间复杂度O(n)  
poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.  
(3)epoll==>时间复杂度O(1)  
epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）  

### 4.分页，分段，段页的区别   

> 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。  
段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定。  
段向用户提供二维地址空间；页向用户提供的是一维地址空间。  
段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。
    
段与页之间的区别：
> 第一种是，你从本子的第一张纸开始用，并且事先在本子上做划分：第2张到第30张纸记语文笔记，第31到60张纸记数学笔记，第61到100张纸记英语笔记，最后在第一张纸做个列表，记录着三门笔记各自的范围。这就是分段管理，第一张纸叫段表。   
第二种是，你从第二张纸开始做笔记，各种课的笔记是连在一起的：第2张纸是数学，第3张是语文，第4张英语……最后呢，你在第一张纸做了一个目录，记录着语文笔记在第3、7、14、15张纸……，数学笔记在第2、6、8、9、11……，英语笔记在第4、5、12……。这就是分页管理，第一张纸叫页表。你要复习哪一门课，就到页表里查寻相关的纸的编号，然后翻到那一页去复习

### 5.操作系统的作用和功能   

> **OS是用户和计算机硬件系统之间的结构**  
OS位于用户和计算机硬件系统之间，使用户可以快速、准确、可靠地操作计算机硬件以及运行自己的程序。用户有三种方式使用计算机：命令（直接使用操作系统提供的命令来使用计算机硬件）、系统调用（编写一段C程序，通过操作系统提供的系统调用来使用计算机）、图标-窗口（如在Windows系统中通过双击图标等方式使用计算机）；  
**OS是计算机系统资源的管理者**  
计算机系统中存在多种硬件和软件资源，总体来说这些资源可以分为：处理机、存储器、IO设备以及文件（包括程序和数据），OS的作用就是管理这些系统资源；  
处理机管理：分配和管理；  
存储器管理：内存分配和回收；  
IO设备管理：分配与操作；  
文件管理：存取、共享、保护  
由于多用户同时使用一台计算机时，会发生系统中共享资源需求的冲突。操作系统需要对使用资源的请求作出授权以协调多用户的使用；  
**OS实现了对计算机资源的抽象**  
OS是铺设在计算机硬件上的多层软件的集合；它们不但增强了系统的功能，还隐藏了对硬件操作的细节，实现了对计算机硬件操作的多个层次的抽象模型；随着抽象层次的提高，抽象接口所提供的功能就越强，用户使用起来就越方便；
这里需要注意的是，操作系统将具体的硬件抽象为一组数据结构来实现对硬件的隐藏，并向上提供一组针对这一数据结构的方法来隐藏对硬件的操作。

### 6.死锁的定义以及如何避免死锁(银行家算法)
死锁的定义：
> 死锁是指两个或两个以上线程在执行过程中，由于竞争资源而造成的阻塞问题，若无外力作用下，他们将无法推荐下去，此时系统处于死锁状态。  
互斥条件: 资源每次只能是一个线程使用。 ==》 资源  
请求与保持条件：一个线程因请求资源而阻塞时，对已获取的资源保持不释放。==》线程  
不可剥夺条件：线程已获取的资源，在未使用之前，不能强行剥夺，只能在使用完时由自己释放。  
循环等待条件:若干线程之间形成一种头尾相连接的循环等待资源关系。  

银行家算法：
> 银行家算法是避免死锁的一种重要方法。操作系统按照银行家制定的规则为进程(线程)分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存资源可以满足它的最大需求量，则按当前的申请量分配资源，否则就延迟分配。 当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源，若没有超过则在测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。

例子：
![](https://camo.githubusercontent.com/91b6f9c03034b15dcfef7b7155255ca8a27f5a5b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67)
> 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。  
检查一个状态是否安全的算法如下：  
查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
重复以上两步，直到所有进程都标记为终止，则状态时安全的。
如果一个状态不是安全的，需要拒绝进入这个状态。

### 8.线程/进程模型 
进程：
![](https://img-blog.csdnimg.cn/20190228220042255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsZXhzaGk1,size_16,color_FFFFFF,t_70)
线程：
![](https://img-blog.csdnimg.cn/201903010942464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsZXhzaGk1,size_16,color_FFFFFF,t_70)

### 9.进程间同步与互斥的区别，线程同步的方式   ###

> **同步**  
> 就是协同步调，按预定的先后次序进行运行。如：你说完，我再说。这里的同步千万不要理解成那个同时进行，应是指协同、协助、互相配合。线程同步是指多线程通过特定的设置（如互斥量，事件对象，临界区）来控制线程之间的执行顺序（即所谓的同步）也可以说是在线程之间通过同步建立起执行顺序的关系，如果没有同步，那线程之间是各自运行各自的！  
**线程互斥**  
是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步（下文统称为同步）。


线程同步：  
1.synchronized  
```java
public synchronized void save(){}
synchronized(object){ }
```  
2.volatile  
```java
private volatile int account = 100;
```  
3.重入锁  
```java
        class Bank {            
            private int account = 100;
            //需要声明这个锁
            private Lock lock = new ReentrantLock();
            public int getAccount() {
                return account;
            }
            //这里不再需要synchronized
            public void save(int money) {
                lock.lock();
                try{
                    account += money;
                }finally{
                    lock.unlock();
                }                 
            }
        ｝
```
4.局部变量  
```java
            private static ThreadLocal<Integer> account = new ThreadLocal<Integer>(){
                @Override
                protected Integer initialValue(){
                    return 100;
                }
            };
```
5.阻塞队列  
![](https://pics0.baidu.com/feed/a50f4bfbfbedab647481069a4117e6c578311ea4.jpeg?token=93c32c3e1efa5276f2514a80df0c1c4a&s=CE702ED69EE85F0142D96C5703008062)
```java
private LinkedBlockingQueue<Integer> queue = new LinkedBlockingQueue<Integer>();
```
### 10.动态链接库与静态链接库的区别  


> **一、指代不同**  
1、动态链接库：是微软公司在微软Windows操作系统中，实现共享函数库概念的一种方式。  
2、静态链接库：函数和数据被编译进一个二进制文件（通常扩展名为*.LIB），Visual C++的编译器在链接过程中将从静态库中恢复这些函数和数据并把他们和应用程序中的其他模块组合在一起生成可执行文件。  
**二、特点不同**  
1、动态链接库：库函数的扩展名是 ”.dll"、".ocx"（包含ActiveX控制的库）或者 ".drv"（旧式的系统驱动程序）。  
2、静态链接库：使用的.lib文件，库中的代码最后需要连接到可执行文件中去。  
**三、调用方法不同**  
1、动态链接库：提供了一种使进程可以调用不属于其可执行代码的函数。函数的可执行代码位于一个 DLL 文件中，该 DLL 包含一个或多个已被编译、链接并与使用它们的进程分开存储的函数。  
2、静态链接库：用程序所需的全部内容都是从库中复制了出来，所以静态库本身并不需要与可执行文件一起发行。  


## 三.数据结构
### 1.如何检验链表是否有环  
> 快慢指针

### 2.常用的排序算法(算法复杂度，是否稳定，空间复杂度)   
### 3.二叉树和B树的区别   
> B树是平衡多路查找树，它每个节点包含的关键字增多了，在应用时可利用磁盘块的原理把结点大小限制在磁盘大小范围内从而优化读写速度，同时树的关键字增多后层级比原理的二叉树少量，减少了数据查找次数和复杂度。  
> 二叉树：
![](https://img-blog.csdnimg.cn/20190827175138878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNjEwNjA1,size_16,color_FFFFFF,t_70)  
多叉树：
> 
![](https://img-blog.csdnimg.cn/20190827174919202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNjEwNjA1,size_16,color_FFFFFF,t_70)  
  
> 1.树结构的层级，也就是高度，B树比二叉树更 “ 矮胖 ”；  
> 2.查询效率更快。  
> 例如查找数据15 时：  
> 二叉树 需要 4 次IO操作分别是：  
> 与根节点比较  
> 根节点→12  
> 12→13  
> 13→15  
> B树 需要 3 次IO操作加 1 次内存操作，分别是：  
> 与根节点比较  
> 根节点→12  
> 12→13 15
> 13 15→15 --------- 此时是内存比较，比IO快很多  

### 4.B树和B+树的区别  
> b树：
> 
> ![](https://images0.cnblogs.com/blog/94031/201403/290047034539184.png)  
> b+树：
> 
> ![](https://images0.cnblogs.com/blog/94031/201403/290050025784094.png)  
> 
> B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。  
> B+ 树的优点在于：  
由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。  
B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。  
但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。

### 5.hashMap解决hash冲突的几种方式   

> 1.再散列法  
2.再哈希法  
3.链地址法  
4.建立公共溢出区  

###  6.红黑树和平衡二叉树的区别  

> 1、红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。  
2、平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。

### 7.霍夫曼编码的应用  
> 哈夫曼编码，主要目的是根据使用频率来最大化节省字符（编码）的存储空间

### 8.数组和链表的区别 


> **数组**  
> 在内存中，数组是一块连续的区域  
> 数组需要预留空间   
> **链表**  
> 在内存中，元素的空间可以在任意地方，空间是分散的，不需要连续  
> 空间不需要提前指定大小，是动态申请的，根据需求动态的申请和删除内存空间，扩展方便，故空间的利用率较高
> 链表的空间是从堆中分配的  
![](https://img-blog.csdnimg.cn/2019032716242876.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phc21pbmV4amY=,size_16,color_FFFFFF,t_70)
### 9.10w条数据如何找出前一百条频繁数据  

> **方法1**  
先取出前100个数，维护一个100个数的最小堆，遍历一遍剩余的元素，在此过程中维护堆就可以了。  
具体步骤如下： step1：取前m个元素（例如m=100），建立一个小顶堆。保持一个小顶堆得性质的步骤，运行时间为O（lgm);建立一个小顶堆运行时间为m*O（lgm）=O(m lgm);   
step2:顺序读取后续元素，直到结束。每次读取一个元素，如果该元素比堆顶元素小，直接丢弃 如果大于堆顶元素，则用该元素替换堆顶元素，然后保持最小堆性质。最坏情况是每次都需要替换掉堆顶的最小元素，因此需要维护堆的代价为(N-m) \* O(lgm); 最后这个堆中的元素就是前最大的10W个。时间复杂度为O(N lgm）。  
**方法2**  
把一亿个数字的前100个 首先放入数组。 然后把最小值放在ary[0]。
然后再，循环100到一亿 之间的。 每次循环判断当前数字是否大于ary[0]
当大于时，当前数字放入ary[0] 并再次重构数组最小值进入ary[0]  以此类推 。
当循环完这一亿个数字后。 最大的前100个数字就出来了。

### 10.100个有序数列如何合成一个大数组  
> 归并排序

## 四.java基础
![](https://pics0.baidu.com/feed/f603918fa0ec08fa3e7e5abdf372a66b54fbdad5.jpeg?token=1db6eaad9406aaf3b0fc3a4c6129d062)
### 1.HashMap底层原理(一定要看源码)  
> HashMap底层就是一个数组结构，数组中的每一项又是一个链表。数组+链表结构，新建一个HashMap的时候，就会初始化一个数组。Entry就是数组中的元素，每个Entry其实就是一个key-value的键值对，它持有一个指向下一个元素的引用，这就构成了链表，HashMap底层将key-value当成一个整体来处理，这个整体就是一个Entry对象。HashMap底层采用一个Entry[]数组来保存所有的key-value键值对，当需要存储一个Entry对象时，会根据hash算法来决定在其数组中的位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry对象时，也会根据hash算法找到其在数组中的存储位置， 在根据equals方法从该位置上的链表中取出Entry;
![](https://img-blog.csdnimg.cn/20190703141758870.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lhb19zaGVuX3l1bg==,size_16,color_FFFFFF,t_70)

### 2.有序集合有哪些  

> 实现了 List 接口的集合类全部有序：比如ArrayList、LinkedList  
LinkedHashMap：在 HashMap 的基础上多维护了一个双向链表。  
ConcurrentSkipListMap：基于跳表实现，跳表内所有的元素都是排序的。  
TreeMap：基于红黑树实现。  
TreeSet：基于TreeMap实现。  

### 3.jvm内存模型(线程私有和线程共享内存分别是什么)  
![](https://img-blog.csdn.net/20180711221632221?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F6cWFuemM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)  

> 程序计数器(线程私有)  
是当前线程锁执行字节码的行号治时期，每条线程都有一个独立的程序计数器，这类内存也称为“线程私有”的内存。正在执行java方法的话，计数器记录的是虚拟机字节码指令的地址(当前指令的地址)。如果是Natice方法，则为空。  


> java 虚拟机栈(线程私有)  
每个方法在执行的时候也会创建一个栈帧，存储了局部变量，操作数，动态链接，方法返回地址。  
每个方法从调用到执行完毕，对应一个栈帧在虚拟机栈中的入栈和出栈。  
通常所说的栈，一般是指在虚拟机栈中的局部变量部分。  
局部变量所需内存在编译期间完成分配，  
如果线程请求的栈深度大于虚拟机所允许的深度，则StackOverflowError。  
如果虚拟机栈可以动态扩展，扩展到无法申请足够的内存，则OutOfMemoryError。  


> 本地方法栈（线程私有）  
和虚拟机栈类似，主要为虚拟机使用到的Native方法服务。也会抛出StackOverflowError 和OutOfMemoryError。


> Java堆（线程共享）  
被所有线程共享的一块内存区域，在虚拟机启动的时候创建，用于存放对象实例。  
对可以按照可扩展来实现（通过-Xmx 和-Xms 来控制）  
当队中没有内存可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。  
 

> 方法区（线程共享）  
被所有方法线程共享的一块内存区域。  
用于存储已经被虚拟机加载的类信息，常量，静态变量等。  
这个区域的内存回收目标主要针对常量池的回收和堆类型的卸载。  

### 4.gc算法，垃圾收集器有哪些(g1收集器非常重要)  

> **标记-清除算法**   
**复制算法**   
**标记-整理算法**   
**分代收集算法** 


> **垃圾收集器**  
**Serial收集器**  
**ParNew收集器**  
**Parallel Scavenge收集器**  
**Serial Old收集器**  
**Parallel Old收集器**  
**CMS收集器**  
**G1收集器**   
基于“标记-整理”算法实现收集器
非常精确地控制停顿
区域划分、有优先级的区域回收，保证了G1收集器在有限的时间内可以获得最高的收集效率。

link： https://blog.csdn.net/clover_lily/article/details/80160726


### 5.如何控制线程并发安全 

> 栈封闭   
无状态   
final不可变  
私有及不改变性  
volatile  
加锁/CAS  
安全发布  
ThreadLocal  

link： https://blog.csdn.net/newbie0107/article/details/101646772

### 6.线程安全的集合有哪些(各种集合类的比较，如HashTable和ConcurrentHashMap之间的区别和效率差异)  

> 线程安全工作原理 
jvm中有一个main memory对象，每一个线程也有自己的working memory，一个线程对于一个变量variable进行操作的时候， 都需要在自己的working memory里创建一个copy,操作完之后再写入main memory。 当多个线程操作同一个变量variable，就可能出现不可预知的结果。  
而用synchronized的关键是建立一个监控monitor，这个monitor可以是要修改的变量，也可以是其他自己认为合适的对象(方法)，然后通过给这个monitor加锁来实现线程安全，每个线程在获得这个锁之后，要执行完加载load到working memory 到 use && 指派assign 到 存储store 再到 main memory的过程。才会释放它得到的锁。这样就实现了所谓的线程安全。  


> 线程安全(Thread-safe)的集合对象：  
Vector 
HashTable 
StringBuffer 


> 非线程安全的集合对象：  
ArrayList 
LinkedList
HashMap
HashSet
TreeMap
TreeSet
StringBulider

link: https://www.cnblogs.com/huangdabing/p/9249233.html

### 7.java中常见的锁(乐观锁悲观锁)  
![](https://img-blog.csdnimg.cn/20181122101753671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F4aWFvYm9nZQ==,size_16,color_FFFFFF,t_70)

乐观锁与悲观锁（cas算法）：
![](https://img-blog.csdnimg.cn/20181122101819836.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F4aWFvYm9nZQ==,size_16,color_FFFFFF,t_70)

link https://www.cnblogs.com/jyroy/p/11365935.html
### 8.synchronized和lock有什么区别 

> Lock是一个接口，而synchronized是关键字。  
synchronized会自动释放锁，而Lock必须手动释放锁。  
Lock可以让等待锁的线程响应中断，而synchronized不会，线程会一直等待下去。  
通过Lock可以知道线程有没有拿到锁，而synchronized不能。  
Lock能提高多个线程读操作的效率。  
synchronized能锁住类、方法和代码块，而Lock是块范围内的。  



> synchronized原始采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。



> 而Lock用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。

link: https://blog.csdn.net/hefenglian/article/details/82383569
### 9.可重入锁和非可重入锁的区别  



> 可重入锁就是一个类的A、B两个方法，A、B都有获得统一把锁，当A方法调用时，获得锁，在A方法的锁还没有被释放时，调用B方法时，B方法也获得该锁。
这种情景，可以是不同的线程分别调用这个两个方法。也可是同一个线程，A方法中调用B方法，这个线程调用A方法。
synchronized和java.util.concurrent.locks.ReentrantLock是可重入锁。


> 不可重入锁就是一个类的A、B两个方法，A、B都有获得统一把锁，当A方法调用时，获得锁，在A方法的锁还没有被释放时，调用B方法时，B方法也获得不了该锁，必须等A方法释放掉这个锁。

example: https://blog.csdn.net/weixin_41549033/article/details/99685331
### 10.线程池的七个参数，线程池的好处  
![](https://img-blog.csdnimg.cn/20190423104753143.png)

> corePoolSize 线程池核心线程大小  
maximumPoolSize 线程池最大线程数量  
keepAliveTime 空闲线程存活时间  
unit 空间线程存活时间单位  
workQueue 工作队列  
threadFactory 线程工厂  
handler 拒绝策略(四种）  

link: https://blog.csdn.net/ye17186/article/details/89467919


> **好处**  
利用线程池管理并复用线程、控制最大并发数等。  
实现任务线程队列缓存策略和拒绝机制。  
实现某些与时间相关的功能，如定时执行、周期执行等。  
隔离线程环境。比如，交易服务和搜索服务在同一台服务器上，分别开启两个线程池，交易线程的资源消耗明显要大；因此，通过配置独立的线程池，将较慢的交易服务与搜索服务隔开，避免个服务线程互相影响。  
### 11.java中有哪些常用的线程池  

> newFixedThreadPool  
newCachedThreadPool  
newSingleThreadExecutor  
newScheduledThreadPool  

link: https://www.cnblogs.com/xichji/p/11757110.html
### 12.jvm类加载过程  
> 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。  
> ![](https://img-blog.csdn.net/20170907001317206?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2lsZW5jZU9P/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

link: https://blog.csdn.net/qq_35114086/article/details/80371859
### 13.反射的原理，有什么应用  

> 原理：反射首先是能够获取到Java中的反射类的字节码，然后将字节码中的方法，变量，构造函数等映射成 相应的 Method、Filed、Constructor 等类  
应用：取出类的modifiers,数据成员,方法,构造器,和超类
找出某个接口里定义的常量和方法说明.
取得和设定对象数据成员的值,如果数据成员名是运行时刻确定的也能做到.
在运行时刻调用动态对象的方法.

link：https://blog.csdn.net/fhkkkbfgggjk/java/article/details/85307922
### 14.java如何打破双亲委派  
![](https://img-blog.csdn.net/20180406132228571?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveWFuZ2d1b3Ni/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)  

> 双亲委派模型工作流程  
首先会先查找当前ClassLoader是否加载过此类，有就返回；  
如果没有，查询父ClassLoader是否已经加载过此类，如果已经加载过,就直接返回Parent加载的类；  
如果整个类加载器体系上的ClassLoader都没有加载过，才由当前ClassLoader加载(调用findClass)。  

> 
双亲委派模型的作用  
作用：保证JDK核心类的优先加载；

> 
如何打破双亲委派模型？  
自定义类加载器，重写loadClass方法；  
使用线程上下文类加载器；  
### 15.volatile的作用 

> 保持内存可见性  
防止指令重排 

link: https://www.cnblogs.com/monkeysayhi/p/7654460.html

### 16.线程间如何通信

> 使用 volatile 关键字  
使用Object类的wait() 和 notify() 方法  
使用JUC工具类 CountDownLatch  
基本LockSupport实现线程间的阻塞和唤醒  

link: https://blog.csdn.net/jisuanji12306/article/details/86363390
   
### 17.CAS算法以及可能产生的问题  

> CAS算法  
通常将 CAS 用于同步的方式是从地址 V 读取值 A，执行多步计算来获得新 值 B，然后使用 CAS 将 V 的值从 A 改为 B。如果 V 处的值尚未同时更改，则 CAS 操作成功。


> ABA问题  
例如A线程从内存中取出了1，这时候B线程也从内存中取出了1，但是A线程的执行时间远远小于B线程的执行时间，A线程先把1变成2写回到内存中，又把2变成1再次写回到内存中，这时候B线程开始进行CAS操作的时候发现内存中的值依然是1，然后线程B操作也会成功。但是在这期间B线程操作虽然完成了，但是并不代表这个过程是没有问题的 。


> 循环时间长开销大  
自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。
### 18.乐观锁和悲观锁的区别  
> 见第7
### 19.String，StringBuffer和StringBuilder的区别(String是不可变类有什么好处)


> String -常量  
StringBuffer -变量，效率低，线程安全  
StringBuilder -变量，效率高，线程不安全  
（1）如果要操作少量的数据用 String；  
（2）多线程操作字符串缓冲区下操作大量数据 StringBuffer；  
（3）单线程操作字符串缓冲区下操作大量数据 StringBuilder

![](https://img-blog.csdn.net/20180411092328691?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTEwMTE3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


### 20.为什么String是不可变类，有什么好处  

> 1.由于 String 在 Java 中是不可变的，这样 Java Runtime 就可以**节省大量的 Java 堆空间**，因为不同的 String 变量可以在String Pool中引用相同的 String 变量(实际String对象的值)。  
2.如果String不是不可变的，那么它将对应用程序造成严重的**安全威胁**。 例如，数据库用户名，密码作为String传递以获取数据库连接.如果String是可变的,黑客可以轻松改变它的引用值以导致应用程序中出现安全问题。  
3.由于String是不可变的,所以它在多线程环境(multithreading)是**线程安全**的,一个 String 实例可以在不同的线程中共享。 这避免了使用同步(synchronization)来保护线程安全,String是隐式线程安全的.  
4.String被用在了classloader 类加载器中，不可变性提供了正确的类由**Classloader加载的安全性**。 例如，假设您尝试加载java.sql.Connection类的实例，但引用的值更改为myhacked.Connection类，可以对数据库执行有害的操作。  
5.由于 String 是不可变的，它的 hashcode 在创建时就被缓存了，它不需要再次计算,并且它的**处理速度**比其他 Object对象要快。这也是为什么 HashMap 常用 String 对象作 key的原因。


### 21.如何保证线程顺序执行  
> 使用join()方法，让其他线程等待。使用join的线程会独占执行资源，直到使用完毕，其它线程才能获取执行权。
### 22.sleep和wait的区别  


> 1、sleep是线程中的方法，但是wait是Object中的方法。  
2、sleep方法不会释放lock，但是wait会释放，而且会加入到等待队列中。  
3、sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字。  
4、sleep不需要被唤醒（休眠之后推出阻塞），但是wait需要（不指定时间需要被别人中断）。  
### 23.synchronized锁膨胀过程  
？

### 24.抽象类与接口的区别  


### 25.HashMap和HashTable的区别  

### 26.线程安全的数组有哪些  

### 27.谈谈你对面向对象的理解  

### 28.常用的设计模式  

### 29.HashMap和HashTable的区别  


## 五.MySQL数据库
1.数据库中有哪些索引类型  
2.数据库索引底层实现  
3.为什么选用B+树  
4.hash索引与B+树如何选用  
5.有哪些数据库引擎，各自的区别  
6.怎么对一条查询语句进行调优  
7.聚集索引和非聚集索引的区别  
8.MySQL有哪几种锁，分别怎么实现  
9.MySQL四种隔离引擎，底层实现  
10.什么情况下设置了索引但是会失效  
11.优化数据库的方案  
12.数据库的三大范式  
13.数据库的四大特性  
14.数据库如何解决幻读(mvcc + 间隙锁)  

## 六.Spring以及分布式知识
1.Spring的启动流程  
2.Spring Bean的注入方式  
3.Spring IOC如何实现(DefaultListAbleBeanFactory)  
4.Spring Aop如何实现，有什么作用  
5.Spring事务传播机制有哪几种  
6.Spring Bean的初始化过程  
7.Spring如何解决循环依赖  
8.Spring如何实现懒加载  
9.分布式系统如何实现数据一致性  
10.谈谈你对微服务的理解  
11.负载均衡策略有哪几种方式  
12.SOA和微服务的区别  
13.如何实现分布式锁  
14.如何手写限流算法  
15.CAP理论和base定理  
16.分布式系统需要考虑哪些问题  
17.你的系统你会从哪些方面考虑去优化  
18.你的服务挂了怎么处理  